{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f786e826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 15:11:12.299249: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-12 15:11:12.534846: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-12 15:11:13.388412: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "from datetime import date, timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f09a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "SILVER_DATA = \"data/silver/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "261c2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_WINDOW = 90\n",
    "VALIDATE_FILTER = pl.col(\"date\").gt(date(2025, 7, 1))\n",
    "FORWARD_DAYS_PREDICTION = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4fed6654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pl.read_parquet(SILVER_DATA + \"stock_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e0cf9fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TSLA'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tickers = (\n",
    "    df_raw.with_columns(tmp=pl.col(\"volume\") * pl.col(\"close\"))\n",
    "    .sort(\"date\", descending=True)\n",
    "    .unique(subset=\"ticker\")\n",
    "    .sort(\"tmp\", descending=True)\n",
    "    .select(\"ticker\")\n",
    "    .limit(1)\n",
    "    .to_numpy()[:, 0]\n",
    ")\n",
    "list_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cfb83a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_win_collect(x: str) -> pl.Expr:\n",
    "    return (\n",
    "        pl.col(x)\n",
    "        .over(\n",
    "            partition_by=\"ticker\",\n",
    "            order_by=\"date\",\n",
    "            mapping_strategy=\"join\",\n",
    "            descending=False,\n",
    "        )\n",
    "        .list.slice(\n",
    "            pl.col(\"index\") - CONTEXT_WINDOW,\n",
    "            CONTEXT_WINDOW,\n",
    "        )\n",
    "        .alias(\"context_\" + x)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c4c07e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3_729, 14)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ticker</th><th>date</th><th>high</th><th>low</th><th>open</th><th>close</th><th>volume</th><th>index</th><th>comming_1_day_max</th><th>comming_1_day_min</th><th>context_open</th><th>context_low</th><th>context_high</th><th>context_close</th></tr><tr><td>str</td><td>date</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td><td>f64</td><td>f64</td><td>list[f64]</td><td>list[f64]</td><td>list[f64]</td><td>list[f64]</td></tr></thead><tbody><tr><td>&quot;TSLA&quot;</td><td>2010-11-05</td><td>1.664667</td><td>1.581333</td><td>1.658</td><td>1.629333</td><td>1.5165e7</td><td>91</td><td>1.666667</td><td>1.602</td><td>[1.719333, 1.666667, … 1.506667]</td><td>[1.553333, 1.351333, … 1.476667]</td><td>[2.028, 1.728, … 1.688667]</td><td>[1.588667, 1.464, … 1.66]</td></tr><tr><td>&quot;TSLA&quot;</td><td>2010-11-08</td><td>1.666667</td><td>1.602</td><td>1.633333</td><td>1.665333</td><td>7.6425e6</td><td>92</td><td>1.712667</td><td>1.603333</td><td>[1.666667, 1.533333, … 1.658]</td><td>[1.351333, 1.247333, … 1.581333]</td><td>[1.728, 1.54, … 1.664667]</td><td>[1.464, 1.28, … 1.629333]</td></tr><tr><td>&quot;TSLA&quot;</td><td>2010-11-09</td><td>1.712667</td><td>1.603333</td><td>1.666667</td><td>1.642</td><td>1.4346e7</td><td>93</td><td>1.998</td><td>1.603333</td><td>[1.533333, 1.333333, … 1.633333]</td><td>[1.247333, 1.055333, … 1.602]</td><td>[1.54, 1.333333, … 1.666667]</td><td>[1.28, 1.074, … 1.665333]</td></tr><tr><td>&quot;TSLA&quot;</td><td>2010-11-10</td><td>1.998</td><td>1.603333</td><td>1.632</td><td>1.957333</td><td>4.59075e7</td><td>94</td><td>1.94</td><td>1.822</td><td>[1.333333, 1.093333, … 1.666667]</td><td>[1.055333, 0.998667, … 1.603333]</td><td>[1.333333, 1.108667, … 1.712667]</td><td>[1.074, 1.053333, … 1.642]</td></tr><tr><td>&quot;TSLA&quot;</td><td>2010-11-11</td><td>1.94</td><td>1.822</td><td>1.906667</td><td>1.869333</td><td>2.91795e7</td><td>95</td><td>2.033333</td><td>1.871333</td><td>[1.093333, 1.076, … 1.632]</td><td>[0.998667, 1.038, … 1.603333]</td><td>[1.108667, 1.168, … 1.998]</td><td>[1.053333, 1.164, … 1.957333]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;TSLA&quot;</td><td>2025-08-28</td><td>353.549988</td><td>340.26001</td><td>350.910004</td><td>345.980011</td><td>6.79032e7</td><td>3815</td><td>348.75</td><td>331.700012</td><td>[230.259995, 230.960007, … 351.940002]</td><td>[222.789993, 229.850006, … 349.160004]</td><td>[232.210007, 242.789993, … 355.390015]</td><td>[227.5, 237.970001, … 349.600006]</td></tr><tr><td>&quot;TSLA&quot;</td><td>2025-08-29</td><td>348.75</td><td>331.700012</td><td>347.230011</td><td>333.869995</td><td>8.11457e7</td><td>3816</td><td>333.329987</td><td>325.600006</td><td>[230.960007, 254.860001, … 350.910004]</td><td>[229.850006, 244.429993, … 340.26001]</td><td>[242.789993, 259.450012, … 353.549988]</td><td>[237.970001, 250.740005, … 345.980011]</td></tr><tr><td>&quot;TSLA&quot;</td><td>2025-09-02</td><td>333.329987</td><td>325.600006</td><td>328.230011</td><td>329.359985</td><td>5.8392e7</td><td>3817</td><td>343.329987</td><td>328.51001</td><td>[254.860001, 250.5, … 347.230011]</td><td>[244.429993, 249.199997, … 331.700012]</td><td>[259.450012, 259.540009, … 348.75]</td><td>[250.740005, 259.51001, … 333.869995]</td></tr><tr><td>&quot;TSLA&quot;</td><td>2025-09-03</td><td>343.329987</td><td>328.51001</td><td>335.200012</td><td>334.089996</td><td>8.87333e7</td><td>3818</td><td>338.890015</td><td>331.480011</td><td>[250.5, 261.690002, … 328.230011]</td><td>[249.199997, 259.630005, … 325.600006]</td><td>[259.540009, 286.850006, … 333.329987]</td><td>[259.51001, 284.950012, … 329.359985]</td></tr><tr><td>&quot;TSLA&quot;</td><td>2025-09-04</td><td>338.890015</td><td>331.480011</td><td>336.149994</td><td>338.529999</td><td>6.0711e7</td><td>3819</td><td>355.869995</td><td>344.679993</td><td>[261.690002, 288.980011, … 335.200012]</td><td>[259.630005, 272.420013, … 328.51001]</td><td>[286.850006, 294.859985, … 343.329987]</td><td>[284.950012, 285.880005, … 334.089996]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3_729, 14)\n",
       "┌────────┬────────────┬────────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ ticker ┆ date       ┆ high       ┆ low       ┆ … ┆ context_o ┆ context_l ┆ context_h ┆ context_c │\n",
       "│ ---    ┆ ---        ┆ ---        ┆ ---       ┆   ┆ pen       ┆ ow        ┆ igh       ┆ lose      │\n",
       "│ str    ┆ date       ┆ f64        ┆ f64       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│        ┆            ┆            ┆           ┆   ┆ list[f64] ┆ list[f64] ┆ list[f64] ┆ list[f64] │\n",
       "╞════════╪════════════╪════════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ TSLA   ┆ 2010-11-05 ┆ 1.664667   ┆ 1.581333  ┆ … ┆ [1.719333 ┆ [1.553333 ┆ [2.028,   ┆ [1.588667 │\n",
       "│        ┆            ┆            ┆           ┆   ┆ ,         ┆ ,         ┆ 1.728, …  ┆ , 1.464,  │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 1.666667, ┆ 1.351333, ┆ 1.688667] ┆ … 1.66]   │\n",
       "│        ┆            ┆            ┆           ┆   ┆ …         ┆ …         ┆           ┆           │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 1.50666…  ┆ 1.47666…  ┆           ┆           │\n",
       "│ TSLA   ┆ 2010-11-08 ┆ 1.666667   ┆ 1.602     ┆ … ┆ [1.666667 ┆ [1.351333 ┆ [1.728,   ┆ [1.464,   │\n",
       "│        ┆            ┆            ┆           ┆   ┆ ,         ┆ ,         ┆ 1.54, …   ┆ 1.28, …   │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 1.533333, ┆ 1.247333, ┆ 1.664667] ┆ 1.629333] │\n",
       "│        ┆            ┆            ┆           ┆   ┆ … 1.658]  ┆ …         ┆           ┆           │\n",
       "│        ┆            ┆            ┆           ┆   ┆           ┆ 1.58133…  ┆           ┆           │\n",
       "│ TSLA   ┆ 2010-11-09 ┆ 1.712667   ┆ 1.603333  ┆ … ┆ [1.533333 ┆ [1.247333 ┆ [1.54,    ┆ [1.28,    │\n",
       "│        ┆            ┆            ┆           ┆   ┆ ,         ┆ ,         ┆ 1.333333, ┆ 1.074, …  │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 1.333333, ┆ 1.055333, ┆ …         ┆ 1.665333] │\n",
       "│        ┆            ┆            ┆           ┆   ┆ …         ┆ … 1.602]  ┆ 1.666667] ┆           │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 1.63333…  ┆           ┆           ┆           │\n",
       "│ TSLA   ┆ 2010-11-10 ┆ 1.998      ┆ 1.603333  ┆ … ┆ [1.333333 ┆ [1.055333 ┆ [1.333333 ┆ [1.074,   │\n",
       "│        ┆            ┆            ┆           ┆   ┆ ,         ┆ ,         ┆ ,         ┆ 1.053333, │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 1.093333, ┆ 0.998667, ┆ 1.108667, ┆ … 1.642]  │\n",
       "│        ┆            ┆            ┆           ┆   ┆ …         ┆ …         ┆ …         ┆           │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 1.66666…  ┆ 1.60333…  ┆ 1.71266…  ┆           │\n",
       "│ TSLA   ┆ 2010-11-11 ┆ 1.94       ┆ 1.822     ┆ … ┆ [1.093333 ┆ [0.998667 ┆ [1.108667 ┆ [1.053333 │\n",
       "│        ┆            ┆            ┆           ┆   ┆ , 1.076,  ┆ , 1.038,  ┆ , 1.168,  ┆ , 1.164,  │\n",
       "│        ┆            ┆            ┆           ┆   ┆ … 1.632]  ┆ …         ┆ … 1.998]  ┆ …         │\n",
       "│        ┆            ┆            ┆           ┆   ┆           ┆ 1.603333] ┆           ┆ 1.957333] │\n",
       "│ …      ┆ …          ┆ …          ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ TSLA   ┆ 2025-08-28 ┆ 353.549988 ┆ 340.26001 ┆ … ┆ [230.2599 ┆ [222.7899 ┆ [232.2100 ┆ [227.5,   │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 95, 230.9 ┆ 93, 229.8 ┆ 07, 242.7 ┆ 237.97000 │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 60007, …  ┆ 50006, …  ┆ 89993, …  ┆ 1, …      │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 351…      ┆ 349…      ┆ 355…      ┆ 349.6000… │\n",
       "│ TSLA   ┆ 2025-08-29 ┆ 348.75     ┆ 331.70001 ┆ … ┆ [230.9600 ┆ [229.8500 ┆ [242.7899 ┆ [237.9700 │\n",
       "│        ┆            ┆            ┆ 2         ┆   ┆ 07, 254.8 ┆ 06, 244.4 ┆ 93, 259.4 ┆ 01, 250.7 │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 60001, …  ┆ 29993, …  ┆ 50012, …  ┆ 40005, …  │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 350…      ┆ 340…      ┆ 353…      ┆ 345…      │\n",
       "│ TSLA   ┆ 2025-09-02 ┆ 333.329987 ┆ 325.60000 ┆ … ┆ [254.8600 ┆ [244.4299 ┆ [259.4500 ┆ [250.7400 │\n",
       "│        ┆            ┆            ┆ 6         ┆   ┆ 01,       ┆ 93, 249.1 ┆ 12, 259.5 ┆ 05, 259.5 │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 250.5, …  ┆ 99997, …  ┆ 40009, …  ┆ 1001, …   │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 347.2300… ┆ 331…      ┆ 348…      ┆ 333.…     │\n",
       "│ TSLA   ┆ 2025-09-03 ┆ 343.329987 ┆ 328.51001 ┆ … ┆ [250.5,   ┆ [249.1999 ┆ [259.5400 ┆ [259.5100 │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 261.69000 ┆ 97, 259.6 ┆ 09, 286.8 ┆ 1, 284.95 │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 2, …      ┆ 30005, …  ┆ 50006, …  ┆ 0012, …   │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 328.2300… ┆ 325…      ┆ 333…      ┆ 329.…     │\n",
       "│ TSLA   ┆ 2025-09-04 ┆ 338.890015 ┆ 331.48001 ┆ … ┆ [261.6900 ┆ [259.6300 ┆ [286.8500 ┆ [284.9500 │\n",
       "│        ┆            ┆            ┆ 1         ┆   ┆ 02, 288.9 ┆ 05, 272.4 ┆ 06, 294.8 ┆ 12, 285.8 │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 80011, …  ┆ 20013, …  ┆ 59985, …  ┆ 80005, …  │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 335…      ┆ 328…      ┆ 343…      ┆ 334…      │\n",
       "└────────┴────────────┴────────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw.filter(pl.col(\"ticker\").is_in(list_tickers))\n",
    "df = df.sort(\"ticker\", \"date\")\n",
    "df = df.with_columns(\n",
    "    pl.row_index().over(partition_by=\"ticker\", order_by=\"date\").alias(\"index\"),\n",
    "    # pl.col(\"date\")+timedelta(days=1)\n",
    ")\n",
    "df = df.with_columns(\n",
    "    pl.col(\"high\")\n",
    "    .rolling_max(\n",
    "        window_size=FORWARD_DAYS_PREDICTION + 1,\n",
    "        weights=[1] * (FORWARD_DAYS_PREDICTION) + [0],\n",
    "    )\n",
    "    .over(partition_by=\"ticker\", order_by=\"date\", descending=True)\n",
    "    .alias(f\"comming_{FORWARD_DAYS_PREDICTION}_day_max\"),\n",
    "    pl.col(\"low\")\n",
    "    .rolling_min(\n",
    "        window_size=FORWARD_DAYS_PREDICTION + 1,\n",
    "        weights=[1] * (FORWARD_DAYS_PREDICTION) + [np.inf],\n",
    "    )\n",
    "    .over(partition_by=\"ticker\", order_by=\"date\", descending=True)\n",
    "    .alias(f\"comming_{FORWARD_DAYS_PREDICTION}_day_min\"),\n",
    "    fn_win_collect(\"open\"),\n",
    "    fn_win_collect(\"low\"),\n",
    "    fn_win_collect(\"high\"),\n",
    "    fn_win_collect(\"close\"),\n",
    ")\n",
    "\n",
    "\n",
    "df = df.filter(pl.col(\"index\").gt(CONTEXT_WINDOW) & pl.col(f\"comming_{FORWARD_DAYS_PREDICTION}_day_max\").is_not_null())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "baeaea70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_norm.shape=(3684, 90, 4, 1)\n",
      "train_y_norm.shape=(3684, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "def convert_to_train_data(df_local):\n",
    "    train_x = df_local.select(\n",
    "        \"context_open\",\n",
    "        \"context_low\",\n",
    "        \"context_high\",\n",
    "        \"context_close\",\n",
    "    ).to_numpy()\n",
    "    train_x = np.apply_along_axis(lambda x: np.vstack(x).T, 1, train_x)\n",
    "    train_min = train_x.min(axis=(1, 2), keepdims=True)\n",
    "    train_max = train_x.max(axis=(1, 2), keepdims=True)\n",
    "    train_x_norm = (train_x - train_min) / (train_max - train_min)\n",
    "    train_x_norm = train_x_norm.reshape(*train_x_norm.shape, 1)\n",
    "    print(f\"{train_x_norm.shape=}\")\n",
    "\n",
    "    train_y = df_local.select(\n",
    "        f\"comming_{FORWARD_DAYS_PREDICTION}_day_min\",\n",
    "        f\"comming_{FORWARD_DAYS_PREDICTION}_day_max\",\n",
    "    ).to_numpy()\n",
    "    train_y = (\n",
    "        np.apply_along_axis(lambda x: np.vstack(x).T, 1, train_y)\n",
    "    )\n",
    "    train_y_norm = (train_y - train_min) / (train_max - train_min)\n",
    "    train_y_norm = train_y_norm.reshape(train_y_norm.shape[0], train_y_norm.shape[2],1)\n",
    "    print(f\"{train_y_norm.shape=}\")\n",
    "    train_idx = df_local.select(\"date\")\n",
    "    return (\n",
    "        train_idx,\n",
    "        train_min,\n",
    "        train_max,\n",
    "        train_x_norm,\n",
    "        train_y_norm,\n",
    "    )\n",
    "\n",
    "train_idx, train_min, train_max, train_x, train_y = convert_to_train_data(df.filter(~VALIDATE_FILTER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1082204c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,952</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">61,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">61,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11520</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,474,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │         \u001b[38;5;34m1,952\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │        \u001b[38;5;34m61,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │        \u001b[38;5;34m61,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11520\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,474,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,599,842</span> (6.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,599,842\u001b[0m (6.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,599,842</span> (6.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,599,842\u001b[0m (6.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, InputLayer\n",
    "\n",
    "\n",
    "input_shape = train_x.shape[1:]\n",
    "print(input_shape)\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape))\n",
    "model.add(Conv2D(32, (30, 2), strides=1, activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(32, (30, 2), strides=1, activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(32, (30, 2), strides=1, activation=\"relu\", padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(2))\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mae\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1cea39f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training the model ---\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0424 - mae: 0.1379\n",
      "Epoch 2/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0137 - mae: 0.0868\n",
      "Epoch 3/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0133 - mae: 0.0852\n",
      "Epoch 4/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0121 - mae: 0.0804\n",
      "Epoch 5/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0113 - mae: 0.0778\n",
      "Epoch 6/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0116 - mae: 0.0786\n",
      "Epoch 7/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0104 - mae: 0.0740\n",
      "Epoch 8/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0105 - mae: 0.0755\n",
      "Epoch 9/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0737\n",
      "Epoch 10/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0099 - mae: 0.0737\n",
      "Epoch 11/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0094 - mae: 0.0712\n",
      "Epoch 12/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0097 - mae: 0.0724\n",
      "Epoch 13/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0713\n",
      "Epoch 14/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0087 - mae: 0.0695\n",
      "Epoch 15/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0087 - mae: 0.0700\n",
      "Epoch 16/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0699\n",
      "Epoch 17/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0082 - mae: 0.0678\n",
      "Epoch 18/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0077 - mae: 0.0654\n",
      "Epoch 19/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0072 - mae: 0.0638\n",
      "Epoch 20/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0072 - mae: 0.0640\n",
      "Epoch 21/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0063 - mae: 0.0603\n",
      "Epoch 22/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0588\n",
      "Epoch 23/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0536\n",
      "Epoch 24/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0049 - mae: 0.0529\n",
      "Epoch 25/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0044 - mae: 0.0512\n",
      "Epoch 26/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0491\n",
      "Epoch 27/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0458\n",
      "Epoch 28/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0033 - mae: 0.0439\n",
      "Epoch 29/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0413\n",
      "Epoch 30/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0387\n",
      "Epoch 31/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0370\n",
      "Epoch 32/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0367\n",
      "Epoch 33/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0375\n",
      "Epoch 34/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0365\n",
      "Epoch 35/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0354\n",
      "Epoch 36/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0357\n",
      "Epoch 37/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0321\n",
      "Epoch 38/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0319\n",
      "Epoch 39/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0293\n",
      "Epoch 40/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0285\n",
      "Epoch 41/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0291\n",
      "Epoch 42/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0296\n",
      "Epoch 43/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0317\n",
      "Epoch 44/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0339\n",
      "Epoch 45/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0290\n",
      "Epoch 46/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0272\n",
      "Epoch 47/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0249\n",
      "Epoch 48/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0261\n",
      "Epoch 49/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0010 - mae: 0.0246    \n",
      "Epoch 50/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 9.9413e-04 - mae: 0.0243\n",
      "Epoch 51/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0259\n",
      "Epoch 52/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0305\n",
      "Epoch 53/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0294\n",
      "Epoch 54/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0276\n",
      "Epoch 55/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0257\n",
      "Epoch 56/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.8847e-04 - mae: 0.0217\n",
      "Epoch 57/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.6222e-04 - mae: 0.0199\n",
      "Epoch 58/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.9897e-04 - mae: 0.0202\n",
      "Epoch 59/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.7942e-04 - mae: 0.0185\n",
      "Epoch 60/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.6622e-04 - mae: 0.0196\n",
      "Epoch 61/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0315\n",
      "Epoch 62/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0304\n",
      "Epoch 63/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 9.4081e-04 - mae: 0.0235\n",
      "Epoch 64/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.0759e-04 - mae: 0.0204\n",
      "Epoch 65/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.8858e-04 - mae: 0.0215\n",
      "Epoch 66/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.7899e-04 - mae: 0.0210\n",
      "Epoch 67/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.3962e-04 - mae: 0.0192\n",
      "Epoch 68/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 9.5473e-04 - mae: 0.0230\n",
      "Epoch 69/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 8.2199e-04 - mae: 0.0215\n",
      "Epoch 70/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.6396e-04 - mae: 0.0207\n",
      "Epoch 71/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.2556e-04 - mae: 0.0205\n",
      "Epoch 72/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.8200e-04 - mae: 0.0199\n",
      "Epoch 73/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.4922e-04 - mae: 0.0178\n",
      "Epoch 74/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.7206e-04 - mae: 0.0200\n",
      "Epoch 75/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.2829e-04 - mae: 0.0190\n",
      "Epoch 76/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 8.1581e-04 - mae: 0.0216\n",
      "Epoch 77/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 8.5686e-04 - mae: 0.0221\n",
      "Epoch 78/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.4523e-04 - mae: 0.0178\n",
      "Epoch 79/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.3245e-04 - mae: 0.0171\n",
      "Epoch 80/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.5913e-04 - mae: 0.0162\n",
      "Epoch 81/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.8623e-04 - mae: 0.0197\n",
      "Epoch 82/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 8.9340e-04 - mae: 0.0225\n",
      "Epoch 83/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 9.3021e-04 - mae: 0.0231\n",
      "Epoch 84/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0252\n",
      "Epoch 85/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.2662e-04 - mae: 0.0198\n",
      "Epoch 86/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0255\n",
      "Epoch 87/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0252\n",
      "Epoch 88/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.5113e-04 - mae: 0.0172\n",
      "Epoch 89/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 3.2980e-04 - mae: 0.0136\n",
      "Epoch 90/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 2.1531e-04 - mae: 0.0112\n",
      "Epoch 91/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.9531e-04 - mae: 0.0104\n",
      "Epoch 92/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.8903e-04 - mae: 0.0102\n",
      "Epoch 93/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 2.4329e-04 - mae: 0.0118\n",
      "Epoch 94/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 3.5567e-04 - mae: 0.0144\n",
      "Epoch 95/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.2463e-04 - mae: 0.0158\n",
      "Epoch 96/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.0047e-04 - mae: 0.0186\n",
      "Epoch 97/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.8620e-04 - mae: 0.0195\n",
      "Epoch 98/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.0001e-04 - mae: 0.0186\n",
      "Epoch 99/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.5931e-04 - mae: 0.0179\n",
      "Epoch 100/100\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.1912e-04 - mae: 0.0156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a3bce332550>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n--- Training the model ---\")\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "99cc69fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_norm.shape=(42, 90, 4, 1)\n",
      "train_y_norm.shape=(42, 2, 1)\n",
      "\n",
      "--- Making a prediction ---\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0066 - mae: 0.0661\n",
      "loss=0.006565130781382322 , mae=0.06608875095844269\n"
     ]
    }
   ],
   "source": [
    "valid_idx, valid_min, valid_max, valid_x, valid_y = convert_to_train_data(\n",
    "    df.filter(VALIDATE_FILTER).filter(\n",
    "        pl.col(\"close\")\n",
    "        < pl.col(\n",
    "            f\"comming_{FORWARD_DAYS_PREDICTION}_day_max\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(\"\\n--- Making a prediction ---\")\n",
    "\n",
    "loss, mae = model.evaluate(valid_x, valid_y)\n",
    "print(f\"{loss=} , {mae=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5acad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=0.006565130781382322 , mae=0.06608875095844269\n",
    "loss=0.0072648185305297375 , mae=0.07034825533628464\n",
    "loss=0.017060449346899986 , mae=0.1299811601638794\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "39856c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/stepWARNING:tensorflow:5 out of the last 143 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a3bce0f2ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1b359c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_signal = valid_x[:, -1]\n",
    "last_signal = last_signal * (valid_max - valid_min) + valid_min\n",
    "last_signal = last_signal.squeeze()\n",
    "prediction_denomalized = (\n",
    "    prediction.reshape(*prediction.shape, 1) * (valid_max - valid_min) + valid_min\n",
    ")\n",
    "prediction_denomalized = prediction_denomalized.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f0034d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (45, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th></tr><tr><td>date</td></tr></thead><tbody><tr><td>2025-07-02</td></tr><tr><td>2025-07-03</td></tr><tr><td>2025-07-07</td></tr><tr><td>2025-07-08</td></tr><tr><td>2025-07-09</td></tr><tr><td>&hellip;</td></tr><tr><td>2025-08-28</td></tr><tr><td>2025-08-29</td></tr><tr><td>2025-09-02</td></tr><tr><td>2025-09-03</td></tr><tr><td>2025-09-04</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (45, 1)\n",
       "┌────────────┐\n",
       "│ date       │\n",
       "│ ---        │\n",
       "│ date       │\n",
       "╞════════════╡\n",
       "│ 2025-07-02 │\n",
       "│ 2025-07-03 │\n",
       "│ 2025-07-07 │\n",
       "│ 2025-07-08 │\n",
       "│ 2025-07-09 │\n",
       "│ …          │\n",
       "│ 2025-08-28 │\n",
       "│ 2025-08-29 │\n",
       "│ 2025-09-02 │\n",
       "│ 2025-09-03 │\n",
       "│ 2025-09-04 │\n",
       "└────────────┘"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f7e48748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (45, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>max</th><th>min</th><th>open</th><th>closed</th><th>prediction_min</th><th>prediction_max</th></tr><tr><td>date</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2025-09-04</td><td>343.329987</td><td>328.51001</td><td>335.200012</td><td>334.089996</td><td>339.644176</td><td>350.084406</td></tr><tr><td>2025-09-03</td><td>333.329987</td><td>325.600006</td><td>328.230011</td><td>329.359985</td><td>326.867044</td><td>335.65712</td></tr><tr><td>2025-09-02</td><td>348.75</td><td>331.700012</td><td>347.230011</td><td>333.869995</td><td>339.768521</td><td>340.965087</td></tr><tr><td>2025-08-29</td><td>353.549988</td><td>340.26001</td><td>350.910004</td><td>345.980011</td><td>342.15752</td><td>350.520247</td></tr><tr><td>2025-08-28</td><td>355.390015</td><td>349.160004</td><td>351.940002</td><td>349.600006</td><td>339.829529</td><td>353.419778</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2025-07-09</td><td>304.049988</td><td>294.350006</td><td>297.0</td><td>297.809998</td><td>298.18065</td><td>314.606877</td></tr><tr><td>2025-07-08</td><td>296.149994</td><td>288.769989</td><td>291.369995</td><td>293.940002</td><td>307.411629</td><td>312.860482</td></tr><tr><td>2025-07-07</td><td>318.450012</td><td>312.76001</td><td>317.98999</td><td>315.350006</td><td>314.740358</td><td>327.168098</td></tr><tr><td>2025-07-03</td><td>316.829987</td><td>303.820007</td><td>312.630005</td><td>315.649994</td><td>307.508276</td><td>314.453639</td></tr><tr><td>2025-07-02</td><td>305.890015</td><td>293.209991</td><td>298.459991</td><td>300.709991</td><td>294.971487</td><td>305.550476</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (45, 7)\n",
       "┌────────────┬────────────┬────────────┬────────────┬────────────┬────────────────┬────────────────┐\n",
       "│ date       ┆ max        ┆ min        ┆ open       ┆ closed     ┆ prediction_min ┆ prediction_max │\n",
       "│ ---        ┆ ---        ┆ ---        ┆ ---        ┆ ---        ┆ ---            ┆ ---            │\n",
       "│ date       ┆ f64        ┆ f64        ┆ f64        ┆ f64        ┆ f64            ┆ f64            │\n",
       "╞════════════╪════════════╪════════════╪════════════╪════════════╪════════════════╪════════════════╡\n",
       "│ 2025-09-04 ┆ 343.329987 ┆ 328.51001  ┆ 335.200012 ┆ 334.089996 ┆ 339.644176     ┆ 350.084406     │\n",
       "│ 2025-09-03 ┆ 333.329987 ┆ 325.600006 ┆ 328.230011 ┆ 329.359985 ┆ 326.867044     ┆ 335.65712      │\n",
       "│ 2025-09-02 ┆ 348.75     ┆ 331.700012 ┆ 347.230011 ┆ 333.869995 ┆ 339.768521     ┆ 340.965087     │\n",
       "│ 2025-08-29 ┆ 353.549988 ┆ 340.26001  ┆ 350.910004 ┆ 345.980011 ┆ 342.15752      ┆ 350.520247     │\n",
       "│ 2025-08-28 ┆ 355.390015 ┆ 349.160004 ┆ 351.940002 ┆ 349.600006 ┆ 339.829529     ┆ 353.419778     │\n",
       "│ …          ┆ …          ┆ …          ┆ …          ┆ …          ┆ …              ┆ …              │\n",
       "│ 2025-07-09 ┆ 304.049988 ┆ 294.350006 ┆ 297.0      ┆ 297.809998 ┆ 298.18065      ┆ 314.606877     │\n",
       "│ 2025-07-08 ┆ 296.149994 ┆ 288.769989 ┆ 291.369995 ┆ 293.940002 ┆ 307.411629     ┆ 312.860482     │\n",
       "│ 2025-07-07 ┆ 318.450012 ┆ 312.76001  ┆ 317.98999  ┆ 315.350006 ┆ 314.740358     ┆ 327.168098     │\n",
       "│ 2025-07-03 ┆ 316.829987 ┆ 303.820007 ┆ 312.630005 ┆ 315.649994 ┆ 307.508276     ┆ 314.453639     │\n",
       "│ 2025-07-02 ┆ 305.890015 ┆ 293.209991 ┆ 298.459991 ┆ 300.709991 ┆ 294.971487     ┆ 305.550476     │\n",
       "└────────────┴────────────┴────────────┴────────────┴────────────┴────────────────┴────────────────┘"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction = pl.DataFrame(\n",
    "    {\n",
    "        \"date\": valid_idx,\n",
    "        \"max\": last_signal[:, 2],\n",
    "        \"min\": last_signal[:, 1],\n",
    "        \"open\": last_signal[:, 0],\n",
    "        \"closed\": last_signal[:, 3],\n",
    "        \"prediction_min\": prediction_denomalized[:,0],\n",
    "        \"prediction_max\": prediction_denomalized[:,1],\n",
    "    }\n",
    ").sort(\"date\", descending=True)\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2780d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TSLA\"\t2025-09-04\t338.890015\t331.480011\t336.149994\t338.529999"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
